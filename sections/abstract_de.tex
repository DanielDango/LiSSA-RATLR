
%% LaTeX2e class for student theses
%% sections/abstract_de.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute of Information Security and Dependability
%% Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.6, 2024-06-07
%%
%% Translated by Claude Sonnet 4.5

\Abstract

\Ac{TLR} ist eine wichtige Aufgabe im Software Engineering, die dabei hilft, \TLs zwischen verschiedenen Softwareartefakten zu etablieren und zu pflegen.
Traditionelle \TLR-Methoden basieren häufig auf \IR-Techniken, um Kandidatenlinks zu identifizieren.
Neuere Ansätze verwenden \LLMs, um die Genauigkeit und Rückgewinnungsraten von \TLR zu verbessern.
Um \LLMs jedoch effektiv zu nutzen, ist es entscheidend, geeignete Prompts zu entwickeln.
Dieser Prozess des Prompt Engineering wird oft manuell durchgeführt und ist häufig zeitaufwändig, da er erhebliche Expertise erfordert.

In dieser Arbeit wird ein \APE-Ansatz vorgeschlagen und realisiert, um diese Aufgabe für \TLR im \LiSSAF zu automatisieren.
Unter Verwendung von Feedback aus vorherigen Iterationen werden \LLMs eingesetzt, um Prompts zu verfeinern.
Der Ansatz wird auf fünf Datensätzen aus der \RtR-Aufgabe unter Verwendung von drei verschiedenen \LLMs evaluiert.
Als Baseline werden aktuelle Klassifikationsprompts aus dem \LiSSAF verwendet.

Die Ergebnisse zeigen, dass der realisierte Ansatz die Leistung von \TLR-Aufgaben verbessern kann.
Darüber hinaus wird demonstriert, dass der leistungsstärkste optimierte Prompt für einen Datensatz, gemessen am \fone, auch auf anderen Datensätzen derselben Aufgabe gut funktioniert.
Da die durch diese Arbeit erzielten optimierten Prompts als feste Klassifikationsprompts verwendet werden können, muss der \APE-Algorithmus nicht für jede Evaluierung angewendet werden.
Insgesamt trägt diese Arbeit zum Feld von \TLR bei, indem ein Ansatz für \APE unter Verwendung von \LLMs realisiert wird.

Weitere Forschung kann durchgeführt werden, um mehr Freiheitsgrade für die \APE-Algorithmen zu erforschen.
Der \APE-Ansatz kann auch in anderen \TLR-Domänen, mit verschiedenen Modellen und neuen Prompting-Strategien untersucht werden.
