%% LaTeX2e class for student theses
%% sections/evaluation.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute of Information Security and Dependability
%% Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.6, 2024-06-07

\chapter{Evaluation}
\label{ch:Evaluation}

\Todo{Talk about evaluation in general}


\section{Setup}
\label{sec:Evaluation:setup}
To evaluate the \APE algorithms proposed in \Todo{add link to approach}, a multitude of different datasets will be used.
They are taken from \citewithauthor{hey2025ReplicationPackage}'s replication package.
Some of the gold standard files were modified to provide consistency between artifact naming and the gold standard reference.
The actual contents are not affected by this.
The CCHIT dataset was omitted, as it differs from the others in that it does not link high-level artifacts with low-level artifacts.
An overview of the sets used can be seen in \autoref{tab:dataset_overview}.
\directQuote{Datasets comprise either high-level requirements (HLR), low-level requirements (LLR), requirements (R) or regulatory codes (RC). Percentage of linked source and target artifacts in the gold standard is given in brackets.}{hey2025RequirementsTraceability}

\begin{table}[]
    \centering
    \begin{tabular}{lccccc}
        & \multicolumn{2}{c}{Artifact Type} & \multicolumn{3}{c}{Number of Artifacts} \\
        \cmidrule(lr){ 2-3 } \cmidrule(lr){ 4-6 }
        Dataset   & Source & Target & Source     & Target     & \TLs \\
        \arrayrulecolor{kit-gray30} \midrule \arrayrulecolor{black}
        CM1-NASA  & HLR    & LLR    & 22 (86\%)  & 53 (57\%)  & 45   \\
        Dronology & HLR    & LLR    & 99 (93\%)  & 211 (99\%) & 220  \\
        GANNT     & HLR    & LLR    & 17 (100\%) & 69 (99\%)  & 68   \\
        MODIS     & HLR    & LLR    & 19 (63\%)  & 49 (63\%)  & 41   \\
        WARC      & HLR    & LLR    & 63 (95\%)  & 89 (89\%)  & 136  \\
        \arrayrulecolor{kit-gray30} \midrule \arrayrulecolor{black}
    \end{tabular}
    \caption{Overview of the datasets adjusted from \citeauthor{hey2025RequirementsTraceability}~\cite[Table 1]{hey2025RequirementsTraceability}}
    \label{tab:dataset_overview}
\end{table}


Several \LLMs will be used.
The focus will be on \OAI's \gpt and \gptmini models.
Compared to the locally hosted \codellama and \llama models by Meta AI, they enable faster evaluation with parallel requests instead of limitations through the host-hardware.
\API access is already implemented in the \LiSSAf.
In addition to the four models used by \citewithauthor{hey2025RequirementsTraceability} in their preceding work, current models will also be considered for evaluation.
\OAI recently introduced their \gptf model.

The \LiSSAf enables the usage of different embedding models for evaluation.
However, the singular embedding model which will be used is \ac{text-embedding} by \OAI.
As of this publication, it is the most up-to-date text embedding model by \OAI and was also used by \citeauthor{hey2025RequirementsTraceability}, thus improving comparability.

The similarity retriever in the \LiSSA pipeline will also not be modified for this evaluation.
The default cosine-similarity-retriever will be utilized.
\Todo{What is a cosine similarity retriever?}

Last but not least, the different \APE algorithms presented in \autoref{ch:Approach} will be added as an additional degree of freedom compared to the baseline evaluation.
Depending on the implementation, different variables, such as mainly the optimization prompt, will be introduced.
Unless specified, each evaluation will assume that the model used to optimize the prompt will be used to classify the \TLs later to derive the quantitative metrics for evaluation.


\section{Naive Prompt Optimization}
\label{sec:Evaluation:naive_optimization}

The initial thought people may have when thinking about prompt optimization is to ask the \LLM to optimize the prompt before usage.
To utilize this very simple approach, just two prerequisites are required.
Firstly, we need our prompt, which is to be optimized.
\autoref{prompt:yes_no} was chosen here as the initial prompt.
It is a \KISS binary classification prompt.
As the \LiSSAf has already employed this prompt for their simple classifier, I decided to start the optimization process with this prompt as well.
Secondly, an optimization prompt is needed.
Therefore, \autoref{prompt:initial_optimization} has been arbitrarily selected.
Unlike \autoref{prompt:yes_no}, this prompt has not been used in research yet to my knowledge.
The optimization prompt was designed by me, while implementing the naive prompt optimization approach.
Sentence completion through GitHub Copilot based on the \ac{gpt-copilot} model was also utilized.

\begin{prompt}{\KISS Original}{yes_no}
    \\
    \input{prompts/original-kiss}
\end{prompt}

\begin{prompt}{Simple Optimization Prompt}{initial_optimization}
    \\
    \input{prompts/optimization-prompt-simple}
\end{prompt}

With these two prompts the naive prompt optimization can be evaluated.
The results seemed to be quite consistent across different tested \LLMs.
I will present the optimized prompts by \OAI's \gpt model as an example of these.
\Todo{Add other models' outputs to the appendix?}

\subsection{Optimized Prompt Analysis}
\label{subsec:Evaluation:naive_optimization:optimized-prompt-analysis}
The first application of the optimization prompt usually yielded an inclusion of the source and target types into the text of the prompt.
This was possible as a set of training data was also provided for following, more sophisticated, prompt optimization approaches.
Further, the very simple classification question \Quote[\autoref{prompt:yes_no}]{Are they related?} was also expanded to be more specific for the \TLR problem.
The result can be seen in \autoref{prompt:yes_no_simple}.
The optimized prompt only depends on the input prompt and the domain of the source and target elements.
This very prompt thus is used for all simple \gpt evaluations in \autoref{tab:naive_optimization} for the domain of \RtR.

\begin{prompt}{\KISS Single Optimization Step}{yes_no_simple}
    \\
    \input{prompts/SimpleAndRepeatedOptimization/results-prompt-optimizationWARC_simple_gpt_gpt-4o-2024-08-06_0.json_411c69c3-cec3-3948-ad97-bb474536d21c}
\end{prompt}

As seen in \autoref{tab:naive_optimization}, application of the optimization prompt in the column \Quote[\autoref{tab:naive_optimization}]{simple} seems to generally improve the \fone.
By repeatedly applying the optimization prompt to the optimized prompt of the previous iteration, we can push this optimization further.
This yields \autoref{prompt:yes_no_iterative}
This particular prompt was again generated by \gpt using five iteration steps.
Once more, the behavior of different \LLMs is quite similar here.
We can see that mostly longer and more detailed instructions are included on how to find \TLs.
However, unfortunately, this prompt does not necessarily perform better for our task.
The performance of this prompt, as seen in \autoref{tab:naive_optimization}, seems to be generally worse than just the singular optimization application.

\begin{prompt}{\KISS Iterative Dumb Optimization}{yes_no_iterative}
    \\
    \input{prompts/SimpleAndRepeatedOptimization/results-prompt-optimizationWARC_iterative_gpt_gpt-4o-2024-08-06_0.json_e81eaea6-576b-337c-8a98-f2e65913a143}
\begin{prompt}{\KISS Iterative Dumb Optimization \llama}{yes_no_llama}
    \\
    \input{prompts/SimpleAndRepeatedOptimization/results-prompt-optimizationWARC_iterative_ollama_llama3.1_8b-instruct-fp16_0.json_28d45aa7-dc74-3651-942a-c21f7ab1e001}
\end{prompt}

However, unfortunately, this prompt does not necessarily perform better for our task.
The performance of this prompt, as seen in the \Quote[\autoref{tab:naive_optimization}]{iterative} column, seems to be generally worse than just the singular optimization application.
What is especially noteworthy, is that for \llama the classification fails completely with this prompt.
We can see in \autoref{prompt:yes_no_llama} that the prompt manged to modify the output format into different types of relationships.
The current classifiers of the \LiSSA project expect the \LLM output to include the classification result clearly as \textquotesingle yes \textquotesingle or \textquotesingle no \textquotesingle.
Thus, while this more detailed classification of the \LLM might even improve performance, it can not be properly evaluated.
\Todo{Consider how this might be mitiaged}

\begin{prompt}{\KISS Iterative Dumb Optimization \llama}{yes_no_llama}
    \\
    \input{prompts/SimpleAndRepeatedOptimization/results-prompt-optimizationWARC_iterative_ollama_llama3.1_8b-instruct-fp16_0.json_28d45aa7-dc74-3651-942a-c21f7ab1e001}
\end{prompt}

\subsection{Systematic Evaluation Results}
\label{subsec:Evaluation:naive_optimization:systematic-evaluation-results}

The systematic evaluation results for varying models and datasets can be found in \autoref{tab:naive_optimization}.
The average and weighted average are also included.
The average value is computed across all datasets, while the weighted average factors the dataset size in as well.
The amount of \TLs in the gold standard reference for the dataset, seen in \autoref{tab:dataset_overview}, is used as the metric for dataset size.

\begin{table}
    \centering
    \renewcommand{\arraystretch}{1.4}
    \input{tables/SimpleAndRepeatedOptimization}
    \renewcommand{\arraystretch}{1}
    \caption{Naive prompt optimization approach prompting the model to optimize the classification prompt}
    \label{tab:naive_optimization}
\end{table}

\newpage


\section{Simple Feedback Optimization}
\label{sec:Evaluation:simple_feedback_optimization}

The following parameters in \autoref{eq:feedback_parameters} will be used to describe prompts for this section.
They can be used as configuration parameters for the feedback optimization process.

\begin{equation}
    \label{eq:feedback_parameters}
    \begin{aligned}
        iter := & \ \text{maximum iterations} \\
        & \ \text{the prompt will be optimized $mi$ times} \\
        n :=    & \ \text{feedback sample size} \\
        & \ \text{$n$ examples of misclassified \TLs will be provided}
    \end{aligned}
\end{equation}

In addition to the optimization prompt used in \autoref{sec:Evaluation:naive_optimization}, an extended optimization prompt will be used here.
\autoref{prompt:feedback_initial} shows the additional details included in this prompt, which is added to the optimization prompt \autoref{prompt:initial_optimization} of \autoref{sec:Evaluation:naive_optimization}.
This will provide the \LLM with more context on where the prompt failed to classify correctly.
The misclassified \TLs will be provided as additional context.
The \LLM can then use this information to improve the prompt.
Up to $n$ misclassified \TLs will be provided.
The optimization process will only utilize a subset of the dataset, as explained in \autoref{sec:Approach} \Todo{fix ref}.
So it is possible that less than $n$ misclassified \TLs are available.
The parameter $mi$ will be used to limit the number of optimization iterations.
In this evaluation section $mi$ was always fully utilized, as the required \fone threshold of $1.0$ for the training subset was never reached.

\begin{prompt}{Feedback Prompt}{feedback_initial}
    \\
    \input{prompts/optimization-prompt-feedback}
\end{prompt}

\subsection{Optimized Prompt Analysis}
\label{subsec:Evaluation:simple_feedback:optimized-prompt-analysis}

As the model now possesses additional knowledge of the dataset through the misclassified \TLs, we can see that they start to diverge more, compared to the naive optimization approach in \autoref{sec:Evaluation:naive_optimization}.
To ease comparison, the results of \gpt are presented here again.
\autoref{prompt:feedback_optimized_3_1} shows the result of one optimization run with $n=3$ and $iter=1$.
Detailed instructions on how to classify \TLs are generated by the \LLM.
This is quite common across different models and parameterizations for the early iterations.
The prompt is also adapted to the \RtR domain as indirectly instructed through the optimization prompt.

\begin{prompt}{Optimized Prompt n = 3, iter = 1}{feedback_optimized_3_1}
    \\
    \input{prompts/FeedbackOptimizer/results-prompt-optimizationWARC_feedback_gpt_gpt-4o-2024-08-06_0_mi1_fs3.json_763f1e98-fde5-3555-8289-67e08e354d5a}
\end{prompt}

However, later iteration steps start to include more overfitted instructions to the provided misclassified \TLs.
During the evaluation, I observed that the optimized prompts of the previous step were often still unable to classify the same \Tls correctly.
\Todo{Can I add evidence for this?}
This is likely contributing to the overfitting of the prompt to the provided misclassified \TLs.
\autoref{prompt:feedback_optimized_5_10} shows the result of one optimization run with $n=5$ and $iter=10$.
The full optimized prompt can be found in the appendix. \Todo{Add to appendix}
The \LLM provided 20 indicators for classification.
Several of these are fitted to the WARC dataset, explicitly mentioning it for example in point ten and eleven for instance.

\begin{prompt}{Optimized Prompt n = 5, iter = 10}{feedback_optimized_5_10}
    \\
    \input{prompts/FeedbackOptimizer/results-prompt-optimizationWARC_feedback_gpt_gpt-4o-2024-08-06_0_mi10_fs5.json_475529c1-57eb-36c3-a3fb-87ea9674a11c}
\end{prompt}

\subsection{Systematic Evaluation Results}
\label{subsec:Evaluation:simple_feedback_optimization:systematic-evaluation-results}

The systematic evaluation results for varying models, datasets, and parameters can be found in \autoref{tab:feedback_optimizer}.
Like in \autoref{subsec:Evaluation:naive_optimization:systematic-evaluation-results}, the average and weighted average are also included.
Noteworthy is that \llama once again fails to comply with the instruction to leave the output format as \textquotesingle yes \textquotesingle or \textquotesingle no \textquotesingle for the dronology dataset. \Todo{Include in Appendix?}
Also compared to the naive optimization approach in \autoref{tab:naive_optimization}, more iteration steps actually provide a benefit.

\begin{landscape}
    \begin{table}
        \centering
        %TODO: Careful, currently the tabularx width is manually replaced with \hsize in the table to adjust to landscape mode
        \renewcommand{\arraystretch}{1}
        \input{tables/FeedbackOptimizer}
        \renewcommand{\arraystretch}{1}
        \caption{Naive prompt optimization approach considering previous misclassified \TLs}
        \label{tab:feedback_optimizer}
    \end{table}
\end{landscape}


\section{Varying the Optimization Prompt}
\label{sec:Evaluation:varying-the-optimization-prompt}
In a recent paper by \citewithauthor{zadenoori2025AutomaticPrompt} the authors discussed the application of \APE for requirement classification.
They took varying initial prompts to run the optimization process with Meta's open source \llama model.
They were able to improve \fone and \ftwo scores by 5 \% and 9 \% respectively to around 80 \%.
Their \APE process is generally aligned with the general iterative optimization loop visualized in \autoref{fig:iterative_core_loop}.

Their prompt is designed to optimize classification prompts by enhancing the explanations of categories within the prompt.
As it also utilizes feedback from misclassified \TLs, it can be used as an alternative optimization prompt for the naive feedback optimization approach.
They used the following optimization prompt in \autoref{prompt:zadenoori_optimization}.
The prompt is tailored to their \CoT classification prompt compromising of a five-step pipeline for requirement classification.

\begin{prompt}{Zadenoori Optimization Prompt}{zadenoori_optimization}
    \\
    \input{prompts/ZadenooriOptimizationPrompt}
\end{prompt}

We can see, that \citeauthor{zadenoori2025AutomaticPrompt} used some similar elements to my optimization prompt.
Just as I instructed the model, that the in and output format are not to be modified, in order to ensure correct classification with the used classifiers, they also included that \Quote[\autoref{prompt:zadenoori_optimization}]{he steps in the optimized prompt must remain exactly the same}.
Further the instruction \Quote[\autoref{prompt:zadenoori_optimization}]{ensure all content remains within the existing steps and does not extend beyond them} is intended to negate behavior such as in \autoref{prompt:feedback_optimized_5_10}.
However, they also gave the \LLM more specific instructions in how to optimize the prompt.
Their classification tasks includes more different outputs than just the simple yes and no of \autoref{prompt:yes_no}.
The \LLM is instructed to add details to these classes.
\autoref{prompt:warc_zandoori_optimized} illustrates what this can look like for our simple \TLR \RtR task.

As their optimization prompt is more detailed than the one used in \autoref{sec:Evaluation:simple_feedback_optimization}, it is used as an alternative optimization prompt for the naive optimization approach.
The initial prompt \autoref{prompt:yes_no} in my work does not incorporate this multistep process.
It needs to be adjusted to be used for \RtR prompt optimization.
\Todo{The modified version of this prompt can be found in the appendix}
As seen in \autoref{tab:zadenoori_optimization} the results of this optimization approach are quite similar to the ones of \autoref{sec:Evaluation:naive_optimization}.

\subsection{Optimized Prompt Analysis}
\label{subsec:Evaluation:varying-the-optimization-prompt:optimized-prompt-analysis}

An optimized prompt generated with the \gpt model for the WARC dataset can be seen in \autoref{prompt:warc_zandoori_optimized}.
We can see, that the \LLM focused on adding explanations to each of the two possible classification results.
While this does include general instructions, overfitting is becoming quite obvious as well.
Some sections from the prompt are specified for the WARC dataset, but might also find appliance elsewhere too.
For instance, a \Quote[\autoref{prompt:warc_zandoori_optimized}]{universal interface to create WARC records and another requirement details the types of WARC records that can be created through such an interface} can be generalized to other applications.
On the other hand solutions are also directly embedded in the prompt.
The phrase \Quote[\autoref{prompt:warc_zandoori_optimized}]{"FR 3" specifies providing functions \[\dots\], and "SRS 7" specifies \[\dots\], they are directly related} is referring to two requirements which are present in the training set.
As such \fone scores during the \APE process on the reduced training set started to diverge more from the actual performance in \autoref{tab:zadenoori_optimization} than the previous prompt in \nameref{sec:Evaluation:simple_feedback_optimization}.

\begin{prompt}{Opimized WARC prompt n = 3, iter = 5}{warc_zandoori_optimized}
    \\
    \input{prompts/ZadenooriOptimizationPrompt/results-prompt-optimizationWARC_feedback_gpt_gpt-4o-2024-08-06_0_mi5_fs3.json_f757620e-36c1-36a1-9314-c0acb1d5432f }
\end{prompt}

\subsection{Systematic Evaluation Results}
\label{subsec:Evaluation:varying-the-optimization-prompt:systematic-evaluation-results}

The systematic evaluation results for varying models, datasets, and parameters can be found in \autoref{tab:zadenoori_optimization}.
Once again the average and weighted average are also included.
The results are quite similar to the naive feedback optimization approach in \autoref{tab:feedback_optimizer}.
The \fone scores are slightly higher on average.
A prevalent issue remains, that more iteration steps often do not yield better results.

\begin{table}
    \centering
    \renewcommand{\arraystretch}{1.4}
    \input{tables/ZadenooriOptimizationPrompt}
    \renewcommand{\arraystretch}{1}
    \caption{Naive prompt optimization approach using the optimization prompt by \citewithauthor{zadenoori2025AutomaticPrompt}}
    \label{tab:zadenoori_optimization}
\end{table}