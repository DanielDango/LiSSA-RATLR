%% LaTeX2e class for student theses
%% sections/abstract_en.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute of Information Security and Dependability
%% Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.6, 2024-06-07

\Abstract

\Ac{TLR} is an important task in software engineering that helps to establish and maintain \TLs between different software artifacts.
Traditional \TLR methods often rely on \IR techniques to identify candidate links.
More novel approaches use \LLMs to improve the accuracy and retrieval rates of \TLR.
However, to utilize \LLMs effectively, it is crucial to design appropriate prompts.
This process of prompt engineering is often done manually and often time-consuming, requiring significant expertise.

In this work, an \APE approach is proposed to automate this task for \TLR in the \LiSSAF.
Using feedback form previous iterations, \LLMs are used to refine prompts.
The approach is evaluated on five datasets from the \RtR task using three different \LLMs.
\Todo{Generell ncohmal auf domain vs task schauen. Domain ist eher sowas wie Healthcare}
As a baseline, current classification prompts from the \LiSSAF are used.

The results show that the proposed approach can improve the performance of \TLR tasks.
However, the improvements are not as significant as initially expected.
\Todo{Nur signifikant verwenden falls Signifikanztests durchgeführt wurden!}
Furthermore, it is demonstrated that the best-performing optimized prompt for a dataset, in terms of \fone, also performs well on other datasets of the same task.
As the optimized prompts yielded by this work can be used as fixed classification prompts, the \APE algorithm is not required to be applied for every evaluation.
Overall, this work contributes to the field of \TLR by realizing an approach to \APE using \LLMs.

Further research can be conducted to explore further configurable settings and to investigate the \APE approach on other \TLR domains, with different models and new prompting strategies.
\Todo{Satzbau/Länge could investigate the APE approach in other TLR domains, with different models, and new prompting strategies .... oder so ähnlich :D}