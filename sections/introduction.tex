%% LaTeX2e class for student theses
%% sections/content.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.6, 2024-06-07

\chapter{Introduction}
\label{ch:Introduction}
During software development, numerous artifacts are created, ranging from the actual project code to documentation and a multitude of formal and informal diagrams.
\TLR aims to link correlating artifacts across different domains or versions.
For instance, a requirement might be implemented in a specific class.
These links are called \TLs.
However, establishing and maintaining these links manually is often done incompletely and inconsistently~\cite{cleland-huang2007BestPractices}.
Further complications, such as inconsistent naming, are frequent issues in software projects~\cite{wohlrab2019ImprovingConsistency}.
\TLR approaches need to be able to deal with these challenges.

\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{graphics/artifact_overview_Fuch√ü}
    \caption{Overview of different artifacts during software development, modified from \citewithauthor{fuchss2025LiSSAGeneric}.}
    Artifacts are presented in white, rounded boxes.
    Existing \TLs between artifacts are highlighted with red dashed arrows.
    The background colors indicate different domains of artifacts.
    \label{fig:artifact_overview}
\end{figure}

\autoref{fig:artifact_overview} provides an overview of what these artifacts might look like.
We can see various snippets of a larger project, including requirements, source code, architectural diagrams, and documentation.
For instance, we have the requirement that a \REST \API should be used.
In the documentation, we can read that \REST is used to process images.
The source code shows us that the \method{Image} class is used by the \method{\REST Facade}.
A \TL exists between the \REST documentation and the \REST requirement.
Furthermore, the documentation snippet describes the relation between the \method{\REST Facade} and \method{Image}.
So a \TL exists between them as well.
We can also note naming inconsistencies for the database.
In the architectural diagram, it is referred to as \method{Database}.
At the same time, the source code uses the abbreviated \method{Db} identifier.
Technically, with just the knowledge displayed in \autoref{fig:artifact_overview}, we can not even be certain that \method{Db} is used to abbreviate database.
The documentation does not mention a database at all.
However, we can infer that \method{Db} is likely a database because it is used in the \method{\REST Facade} class, which is getting images from somewhere.
Thus, the full name database is a reasonable assumption.

This example illustrates that a multitude of factors need to be considered for \TLR.
Aside from or rather especially with naming inconsistencies, we need to consider more information to establish \TLs correctly.
As \LLMs have made rapid advancements in recent years~\cite{zhao2023SurveyLarge}, they have been applied to various tasks in software engineering, including \TLR \cite{fuchss2025LiSSAGeneric, rodriguez2023PromptsMatter}.
Especially \directQuote{\LLMs have demonstrated significant potential in automating and enhancing tasks such as requirement elicitation, classification, generation, specification generation, and quality assessment}{jin2025LLMsLLMbased}.
Yet they are still unable to reason and think on their own~\cite{shojaee2025IllusionThinking}, prompt engineering is required to extract good results~\cite{rodriguez2023PromptsMatter}.
However, manually determining prompts suited for each specific problem is quite a tedious, time- and labor-intensive task.
Our goal is to determine whether current classification prompts can be refined further to improve \TLR rates.
As this proves to be promising, we also want to reduce the overall effort required for \TLR instead of just shifting the task from manual classification to prompt engineering.
To address this shortcoming, \APE tools can be used.
They typically use the \LLM itself to determine suitable adjustments or generate new prompts based on a description or training data of the problem~\cite{ramnath2025SystematicSurvey}.

The \LiSSAf proposes an environment for \TLR tasks, including multiple pipeline steps for the preprocessing of input data.
They harness the power of \LLMs to extract traceability links from a variety of different artifacts, also across multiple tasks.
My work contributes an \APE component to this framework.
It can be used to automatically refine a prompt on a dataset.
The refined prompt can improve \TLR rates, for projects in the \RtR task, compared to the current classification prompts in use by \LiSSA.

This thesis aims to answer the following research questions:
\begin{itemize}
    \item[\textbf{RQ1:}] Can \APE be used to improve \TLR performance in the \LiSSAf?
    \item[\textbf{RQ2:}] How does the performance of optimized prompts compare to the current \TLR performance in the \RtR task?
    \item[\textbf{RQ3:}] Can optimized prompts improve \TLR performance for untrained datasets?
\end{itemize}

The remainder of my work is structured as follows:
\autoref{ch:foundations} introduces the necessary fundamentals.
\autoref{ch:related_work} addresses related work in the fields of \TLR and \APE.
\autoref{ch:Approach} describes the concept of the proposed \APE component.
\autoref{ch:Implementation} details the implementation of the concept.
\autoref{ch:Evaluation} evaluates the implementation and answers the research questions.
Finally, \autoref{ch:Conclusion} concludes the thesis and gives an outlook on possible future work.
A replication package for this thesis is also provided~\cite{schwab2025DanielDangoReplicationPackageAutomatedPromptEngineeringforTraceabilityLinkRecovery}.
