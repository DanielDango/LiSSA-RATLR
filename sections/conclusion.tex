%% LaTeX2e class for student theses
%% sections/conclusion.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute of Information Security and Dependability
%% Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.6, 2024-06-07

\chapter{Conclusion}
\label{ch:Conclusion}

This thesis presents an \APE approach using \LLMs to optimize prompts for \RtR \TLR tasks in the \LiSSAF.
To realize this, a new prompt optimization component is proposed for the \LiSSAF.
Among other strategies for \APE, the gradient descent based algorithm \ProTeGi is implemented.
Utilizing the added \promptoptimizer component, prompts can be refined iteratively to provide better classification results on a training set.
In addition, the naive strategies of prompting the \LLM to optimize the prompt with or without examples of misclassified \TLs are also presented.
The approach is evaluated on up to five datasets from the \RtR domain using four distinct \LLMs.
The results show that the proposed approach can slightly improve the performance of \TLR tasks compared to the baseline classification prompts currently used in the \LiSSAF.
At the same time the variance between the different \APE algorithms \TLR performances is quite small.
\Todo{Das kannst du doch ausrechnen oder? Da waren ja mal so Mathemodule... Sollen ja nicht nur absolut verglichen sein nach Augenma√ü}
Importantly, it is demonstrated that the singular best-performing optimized prompt, \autoref{prompt:optimized_classificiation_prompt} for a dataset also performed well on other datasets of the same domain.
This indicates that the optimized prompts may be used as fixed classification prompts in further work, even if the \APE pipeline is not applied.
\autoref{prompt:optimized_classificiation_prompt} was optimized with the \ProTeGi implementation of the \APE component with the zero-shot \autoref{prompt:yes_no} as initial prompt.
Optimized prompts with the \CoT \autoref{prompt:cot} as initial prompt were not able to outperform the optimized \KISS prompts trained on the same dataset.
\Todo{Check that this statement is still true after adjusting}

As the \LLMs output is not deterministic, the cached requests and responses are included in the \replicationPackage for this thesis.
Small variances in performance are expected when rerunning the requests instead of using the cached values.

Further work might include applying the \APE component to different domains.
Establishing generalized optimized prompts with improved performance on multiple domains is desire bale, as \LiSSA is not restricted to the \RtR domain.
The gradient descent based \APE algorithm still has many more parameters that have been introduced during development, but have not been systematically altered during evaluation.
Exploring configuration variations, for instance utilizing greater optimization budgets, is another possibility to build on this work.
Stepping up from \TLR the optimization prompts used for optimization in the \promptoptimizer component might also be optimized themselves.