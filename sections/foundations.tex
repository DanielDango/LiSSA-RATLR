\chapter{Foundations}
\label{ch:foundations}

To understand the application of automated prompt engineering for \TLR in the \LiSSAF, some key concepts are quite important.
They are explained in the following sections.
First an overview of \TLR is given in \autoref{sec:foundations:tlr}.
Next, the \LiSSAf is introduced in \autoref{sec:foundations:lissa}.
Finally, \APE is explained in \autoref{sec:foundations:ape}, followed by a more detailed explanation of the \ProTeGi algorithm in \autoref{sec:gradient_descent}.
The \ProTeGi algorithm is the basis for the most promising implementation of the \APE component in this work.


\section{Traceability Link Recovery}
\label{sec:foundations:tlr}

According to the Cambridge Dictionary, traceability is \directQuote{the ability to find or follow something}{2025Traceability}.
Meaning, there is evidence of some past occurrence.
In software engineering, \TLs are used to link different software artifacts, which are all varying instances of the same element.
What these elements might look like is visualized in \autoref{fig:artifact_overview}.
Recovery is defined by the Cambridge Dictionary as \directQuote{the process of getting something back}{2025Recovery}.
The combination of these two terms, \TLR, is therefore the process of finding and establishing \TLs between existing software artifacts.
This is necessary as they are often not established or maintained properly~\cite{cleland-huang2007BestPractices}.
These traceability links help track relationships between, for example, code, requirements, diagrams, documentation, and other elements.
This information can be used to ensure consistency between different artifacts and versions.

Finding all or most \TLs in a larger project can be quite a time-consuming task if done manually.
This becomes especially apparent when inconsistencies are introduced into the project's artifacts.
As shown by \citewithauthor{wohlrab2019ImprovingConsistency}, inconsistencies in wording and language are quite common during different stages of development.
For example, naming conventions for architectural components might not be followed during implementation.
They find the impact of these naming inconsistencies to be quite insignificant.
In this case, typically, there will be different naming conventions on each layer, which are followed correspondingly.
This might thus not be much of a hurdle when a human is manually determining \TLs.
However, for automated trace link recovery, this means that simple string comparisons by name are insufficient.
On the other hand the absence of \TLs can also be used as an indicator of inconsistencies.
\citewithauthor{keim2023DetectingInconsistencies} focus on unmentioned model elements and missing model element for software architecture documentation.
They have shown that these inconsistencies can be detected reasonable with \TLR techniques.


\section{Linking Software System Artifacts}
\label{sec:foundations:lissa}

The \LiSSAf by \citeauthor{fuchss2025LiSSAGeneric} proposes a generic framework for \TLR tasks.
The framework is organized in a pipeline structure with several different modules used to process \TLs in a modular manner.
The current \LiSSA evaluation pipeline first retrieves artifacts from the configured providers for the respective source and target domains.
They will be preprocessed with the configured preprocessor into generalized elements.
Importantly elements contain the content of the artifact as text, which will be used in later steps.
Next, embeddings for these elements are created using an embedding model.
\directQuote{Text embeddings are vector representations of natural language that encode its semantic information}{wang2024ImprovingText}
By design semantic similar elements will also have similar embeddings.
Utilizing the elements and their embeddings, \elementstores are initialized.
They provide functionality to search for similar elements based for instance on their embedding vectors.
In the \LiSSA evaluation pipeline, source elements are combined with similar target element candidates in the \classifier module.
They will be prompted to an \LLM to determine whether a \TL exists between the source element and each candidate.
This is done using a classification prompt.
The classification results are then aggregated and post-processed into a set of \TLs.

\begin{prompt}{\KISS by \citewithauthor{ewald2024RetrievalAugmentedLarge} based on \citewithauthor{rodriguez2023PromptsMatter}}{yes_no}
    \\
    \input{prompts/original-kiss}
\end{prompt}

\autoref{prompt:yes_no} shows one of the current default classification prompt used in the \LiSSAf.
It is a zero-shot prompt based on the \KISS principle.
This is the base classification prompt which is optimized during the course of this thesis.


\section{Automated Prompt Engineering}
\label{sec:foundations:ape}

Prompt engineering is the process of refining a prompt for a specific use case.
\Todo{Lass mich raten: Quelle?}
This is typically done in a non-systematic, manual manner.
\Acl{APE} enables \LLMs to refine the initial prompt to optimize their performance~\cite{zadenoori2025AutomaticPrompt}.
Usually, \APE processes are iterated to improve previous results further \citeiterative.
The performance of prompts can be estimated using a set of training data, which consists of textual \iopairs for the \LLM.
The exact content of these pairs depends on the context of the problem for which the prompts are optimized.
For example, sentiment analysis training data might provide pairs consisting of sentences and their correctly identified sentiment.
A prompt performs better the more inputs are correctly mapped onto their expected outputs.

\begin{figure}
    \centering
    \includesvg[width=0.7\linewidth]{graphics/Iterative_core_loop}
    \caption{Visualization of a simple iterative optimization algorithm}
    \label{fig:iterative_core_loop}
    \Todo{Legende einfügen; erklären was die Farben bedeuten etc.}
\end{figure}

As seen in \autoref{fig:iterative_core_loop}, the refinement process will start with some initial prompt.
It needs to be selected first before any optimization can occur.
This prompt can be chosen manually, which is the most straightforward approach.
However, human interaction is still required to choose this first prompt.
\citewithauthor{zhou2023LargeLanguage} propose using \LLMs to automate this process and generate the initial prompt.
They prompt the model to generate a likely set of instructions, also called candidates.
The instructions will achieve good results when prompted with a batch of \iopairs.
These pairs of \io data will be processed as text by the \LLM, pre- and or post-processing may be required.

\Todo{Prüfen ob die Beschreibung zum aktuellen Bild passt}
The initial prompt $p_0$can be optimized using an \LLM in the iterative loop illustrated in \autoref{fig:iterative_core_loop}.
The current prompt $p_i$ will be adjusted to a new prompt $p_{i+1}$ using an optimization prompt.
The optimization prompt will be prompted to the \LLM together with the current prompt $p_i$.
The \LLM will then return a new prompt $p_{i+1}$, which is expected to perform better than $p_i$.
This cycle can be repeated until a fixed number of iterations is reached or the performance of the current prompt $p_i$ exceeds some threshold value.
The final prompt $p_n$ will then be returned as the output of the \APE algorithm.

While this is a very simple and general attempt to \APE, algorithms can of course be more complex as well.


\section{Prompt Optimization with Textual Gradients}
\label{sec:gradient_descent}
\Todo{The entire section}
\citewithauthor{pryzant2023AutomaticPrompt} propose the \ProTeGi algorithm.
\Todo{2.3 sollte so gebaut werden, dass 2.3.1 und 2.3.2 auch eingeführt werden, also um was es darin geht. 2.3 ist irgenwie teil von 2.2 .. da muss man schauen, wie man das kombinieren / abgrenzen kann.}
This entire section is based on their work.

In contrast to the general iterative \APE in \autoref{sec:foundations:ape}, they create multiple improved prompts after each step of the optimization during a single iteration.
This is also illustrated in \autoref{fig:gradient_descent}.
The set of candidates for optimization, the set of improved candidates that corrected previous shortcomings, as well as a set of paraphrased improved candidates, are taken into consideration when selecting the candidates that are carried to the next iteration.
Once any candidate performs better than some threshold value or a maximum number of iterations has been reached, the best performing candidate will be returned as the output of the \ProTeGi algorithm.

\begin{figure}
    \centering
    \includesvg[width=0.7\linewidth]{graphics/gradient_descent}
    \caption{Overview of the iterative optimization loop in~\cite{pryzant2023AutomaticPrompt}}
    \label{fig:gradient_descent}
\end{figure}
\Todo{add legend, symbolise core loop, add description in text, adjust image to fit page better}


The following subsections will explain each step of the \ProTeGi optimization in more detail.
The \ProTeGi algorithm also takes an initial prompt $p_0$ and training data $\{(x_1, y_1), \dots, (x_n, y_n)\}$ consisting of inputs and outputs.
They \directQuote[sec. 2]{assume access to a black box LLM API \idots which returns a likely text continuation y of the prompt formed by concatenating p and x}{pryzant2023AutomaticPrompt}.
They then iteratively optimize the initial prompt $p_0$ to produce an approximation of the most optimized prompt for the given task.
In order to optimize the prompt, a function is required that computes deviance between the actual output $y$ and the expected output $y_i$ as a numeric value.

\subsection{Evaluation and Expansion}
\Todo{Auch hier wäre ein Ablauf gut}
To evaluate the output of the current prompt $p_i$, \citeauthor{pryzant2023AutomaticPrompt} use a loss signal prompt \Todo{Was ist das? Bitte einführen} $\triangledown$, the gradient prompt.
In addition to the prompt, inputs that were not correctly classified when testing $p_i$ are also provided as context for $\triangledown$.
The result summarizes the flaws of $p_i$ in natural language.
This summary is called the textual gradient $g$.
The second prompt $\delta$, the optimization prompt, is required to adjust $p_i$ in the opposite direction of $g$ to minimize the loss signal.

They differ from other iterative implementations by generating multiple gradients and refinements that might improve the classification rate of $p_i$.
In addition, they broaden their candidate prompts further by paraphrasing them into semantically similar prompts, which are worded differently.
Generating new prompts with $g$ and broadening them is considered candidate expansion.

\subsection{Candidate Selection with Multi-Armed Bandit}
To select candidates for the next iteration, \citeauthor{pryzant2023AutomaticPrompt} apply a beam search algorithm.
Beam search is a heuristic best-first graph search algorithm to select a fixed number of promising paths.
The remaining paths will be discarded to allocate resources to more promising paths instead~\cite{BeamSearch}.
A heuristic algorithm finds a good result efficiently, with the trade-off that it is not guaranteed to be optimal.
The selection of the most promising candidates is quite resource-intensive for the entire data set, since many calls to preferably larger \LLMs are required.
As the problem is quite similar to the best arm identification in multi-armed bandit optimization by \citewithauthor{audibert2010BestArm}, they rely on this well-studied problem instead.

The multi-armed bandit problem consists of $N$ stochastically independent probability distributions $\{ D_1, \dots, D_N\}$ with corresponding expected values and variances.
These distributions are unknown to the user initially.
The goal is to maximize the sum of rewards for each pull from the set of probability distributions, utilizing the knowledge gained through previous pulls~\cite{kuleshov2014AlgorithmsMultiarmed}.
It is an analogy to multiple one-armed bandit slot machines.
Pulling a lever on one of these slot machines does not affect the others but costs noticeable resources.
The optimization aims to find the best-performing arms with as few pulls as possible.

\citeauthor{pryzant2023AutomaticPrompt} have used the successive rejects algorithm by \citewithauthor{audibert2010BestArm} to select the best prompt candidates for the next iteration step.
The set of current candidates $S$ is therefore initialized with all $k$ candidate prompts in the iteration step.
Depending on the budget for sampling, candidates and remaining candidates in the set $S$ will be prompted with $n(k)$ pairs of the training data.
The value $n(k)$ depends on the number of remaining candidate prompts.
Other factors, such as a budget to account for pull costs, can also be included.
The results are evaluated with a metric function $m$ to quantify the performance.
For example, $m$ can be a simple binary function as seen in \autoref{eq:sample_binary_metric}.
If the prompt $p$ provides the expected output $y$ for a given input $x$, one is returned.
Otherwise, zero will be returned.

\begin{equation}
    \label{eq:sample_binary_metric}
    m(llm(p, x), y) =
    \begin{cases}
        0, \text{if $llm(p, x) \neq y$}\\
        1, \text{if $llm(p, x) \eq y$}
    \end{cases}
\end{equation}

The lowest scoring prompt is then discarded from $S$ and sampling is repeated with the remainder until the set $S$ only contains the desired amount of candidates.
The remaining candidates will be used as initial prompts for the next expansion step.
This process is called successive rejects.
A pseudocode implementation of this candidate selection algorithm can be seen in \autoref{alg:gradient_descent_select}.


\begin{algorithm}
    \caption{\directQuote[Modified from Algorithm 4, p. 4]{$Select(\cdot)$ with Successive Rejects}{pryzant2023AutomaticPrompt}}
    \label{alg:gradient_descent_select}
    \begin{algorithmic}[1]
        \State Initialize: $S_0 \gets \{p_1, \dots , p_n\}$
        \For{$k = 1, \dots , {n - 1}$}
            \State Sample $D_{sample} \subset D_{tr}, |D_{sample}| = n(k)$
            \State Evaluate $p_i \in S_{k-1}$ with $m(p_i, D_{sample})$
            \State $S_k \gets S_{k-1}$, excluding the prompt with the lowest score from the previous step
        \EndFor
        \State \Return Best prompt $p^* \in S_{n-1}$
    \end{algorithmic}
\end{algorithm}