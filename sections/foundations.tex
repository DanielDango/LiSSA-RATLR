\chapter{Foundations}

To understand the application of automated prompt engineering for \TLR, some key concepts are quite important.
They will be explained in the following subsections.


\section{Definition of Traceability Link Recovery}
Traceability is \directQuote[]{the ability to find or follow something}{2025Traceability}, according to the Cambridge Dictionary.
Meaning, there is evidence of some past occurrence.
The task of \TLR in software engineering is to find instances of the same element across different software artifacts and link them for further processing.
What these elements might look like was visualized in \autoref{fig:artifact_overview}.
These traceability links help track relationships between, for example, code, requirements, diagrams, documentation, and other elements.
This information can be used to ensure consistency between different artifacts and versions.
To find all or most \TLs in a larger project can be quite a time-consuming task if done manually.

This becomes especially apparent when inconsistencies are introduced into the project's artifacts.
As shown by \citewithauthor{wohlrab2019ImprovingConsistency}, inconsistencies in wording and language are quite common during different stages of development.
For example, naming conventions for architectural components might not be followed during implementation.
They find the impact of these naming inconsistencies to be quite insignificant.
In this case, typically, there will be different naming conventions on each layer, which are followed correspondingly.
This might thus not be much of a hurdle when a human is looking for \TLs.
However, for automated trace link recovery, this means that simple string comparisons by name are insufficient.
While \LLMs can overcome these inconsistencies, finding suitable prompts might be challenging or include tedious manual work in prompt engineering. 


\section{Definition of Automated Prompt Engineering}
\label{foundations:sec:automated_prompt_engineering}
Prompt engineering is the process of refining a prompt for a specific use case.
This is typically done in a non-systematic, manual manner. \Acl{APE} enables \LLMs to refine the initial prompt to optimize their performance~\cite{zadenoori2025AutomaticPrompt}.

Typically, \APE processes are iterated to improve previous results further \citeiterative.
An illustration of the core concept and how it can be implemented will be shown in \autoref{approach:sec:naive_iterative} and  \autoref{fig:iterative_core_loop}.

In general, the refinement process will start with some initial prompt.
It needs to be selected first before any optimization can occur.
This prompt can be chosen manually.
This approach is very intuitive.
However, human interaction is still required to choose this first prompt.
\citewithauthor{zhou2023LargeLanguage} propose using \LLMs to automate this process and generate the initial prompt.
They prompt the model to generate a likely set of instructions, also called candidates.
The instructions will achieve good results when prompted with a batch of input/output pairs.
These pairs of input/output data will be processed as text by the \LLM, pre- and or post-processing may be required.

The performance of prompts can be estimated using a set of training data, which consists of textual input/output pairs for the \LLM.
The exact content of these pairs depends on the context of the problem for which the prompts are optimized. 
For example, sentiment analysis training data might provide pairs consisting of sentences and their correctly identified sentiment.
A prompt performs better the more inputs are correctly mapped onto their expected outputs.

While this is a very simple and general attempt to \APE, algorithms can of course be more complex as well.


\section{Automatic Prompt Optimization Using Gradient Descent}
\label{sec:gradient_descent}
\citewithauthor{pryzant2023AutomaticPrompt} propose the \ProTeGi algorithm.
This entire section is based on their work.

In contrast to the general iterative \APE in \autoref{foundations:sec:automated_prompt_engineering}, they create multiple improved prompts after each step of the optimization during a single iteration.
This is also illustrated in \autoref{fig:gradient_descent}.
The set of candidates for optimization, the set of improved candidates that corrected previous shortcomings, as well as a set of paraphrased improved candidates, are taken into consideration when selecting the candidates that are carried to the next iteration.
Once any candidate performs better than some threshold value or a maximum number of iterations has been reached, the best performing candidate will be returned as the output of the \ProTeGi algorithm.

\begin{figure}
\centering
\includesvg[width=0.7\linewidth]{graphics/gradient_descent}
\caption{Overview of the iterative optimization loop in~\cite{pryzant2023AutomaticPrompt}}
\label{fig:gradient_descent}
\end{figure}

\begin{comment}
TODO: 
\begin{itemize}
    \item add legend
    \item symbolise core loop
\end{itemize}
\end{comment}

The following subsections will explain each step of the \ProTeGi optimization in more detail.
The \ProTeGi algorithm also takes an initial prompt $p_0$ and training data $\{(x_1, y_1), \dots, (x_n, y_n)\}$ consisting of inputs and outputs.
They \directQuote[sec. 2]{assume access to a black box LLM API [...] which returns a likely text continuation y of the prompt formed by concatenating p and x}{pryzant2023AutomaticPrompt}.
They then iteratively optimize the initial prompt $p_0$ to produce an approximation of the most optimized prompt for the given task.
In order to optimize the prompt, a function is required that computes deviance between the actual output $y$ and the expected output $y_i$ as a numeric value.


\subsection{Evaluation and Expansion}
To evaluate the output of the current prompt $p_i$, \citeauthor{pryzant2023AutomaticPrompt} use a loss signal prompt $\triangledown$, the gradient prompt.
In addition to the prompt, inputs that were not correctly classified when testing $p_i$ are also provided as context for $\triangledown$.
The result summarizes the flaws of $p_i$ in natural language.
This summary is called the textual gradient $g$.
The second prompt $\delta$, the optimization prompt, is required to adjust $p_i$ in the opposite direction of $g$ to minimize the loss signal.

They differ from other iterative implementations by generating multiple gradients and refinements that might improve the classification rate of $p_i$.
In addition, they broaden their candidate prompts further by paraphrasing them into semantically similar prompts, which are worded differently.
Generating new prompts with $g$ and broadening them is considered candidate expansion.


\subsection{Candidate Selection with  Multi-Armed Bandit}
To select candidates for the next iteration, \citeauthor{pryzant2023AutomaticPrompt} apply a beam search algorithm.
Beam search is a heuristic best-first graph search algorithm to select a fixed number of promising paths.
The remaining paths will be discarded to allocate resources to more promising paths instead~\cite{BeamSearch}.
A heuristic algorithm finds a good result efficiently, with the trade-off that it is not guaranteed to be optimal.
The selection of the most promising candidates is quite resource-intensive for the entire data set, since many calls to preferably larger \LLMs are required.
As the problem is quite similar to the best arm identification in multi-armed bandit optimization by \citewithauthor{audibert2010BestArm}, they rely on this well-studied problem instead.

The multi-armed bandit problem consists of $N$ stochastically independent probability distributions $\{ D_1, \dots, D_N\}$ with corresponding expected values and variances.
These distributions are unknown to the user initially.
The goal is to maximize the sum of rewards for each pull from the set of probability distributions, utilizing the knowledge gained through previous pulls~\cite{kuleshov2014AlgorithmsMultiarmeda}.
It is an analogy to multiple one-armed bandit slot machines.
Pulling a lever on one of these slot machines does not affect the others but costs noticeable resources.
The optimization aims to find the best-performing arms with as few pulls as possible.

\citeauthor{pryzant2023AutomaticPrompt} have used the successive rejects algorithm by \citewithauthor{audibert2010BestArm} to select the best prompt candidates for the next iteration step.
The set of current candidates $S$ is therefore initialized with all $k$ candidate prompts in the iteration step.
Depending on the budget for sampling, candidates and remaining candidates in the set $S$ will be prompted with $n(k)$ pairs of the training data.
The value $n(k)$ depends on the number of remaining candidate prompts.
Other factors, such as a budget to account for pull costs, can also be included.
The results are evaluated with a metric function $m$ to quantify the performance.
For example, $m$ can be a simple binary function as seen in \autoref{eq:sample_binary_metric}.
If the prompt $p$ provides the expected output $y$ for a given input $x$, one is returned.
Otherwise, zero will be returned.

\begin{equation}
\label{eq:sample_binary_metric}
    m(llm(p, x), y) = 
    \begin{cases}
        0, \text{if $llm(p, x) \neq y$}\\
        1, \text{if $llm(p, x) \eq y$}
    \end{cases}
\end{equation}

The lowest scoring prompt is then discarded from $S$ and sampling is repeated with the remainder until the set $S$ only contains the desired amount of candidates.
The remaining candidates will be used as initial prompts for the next expansion step.
This process is called successive rejects.
A pseudocode implementation of this candidate selection algorithm can be seen in \autoref{alg:gradient_descent_select}.


\begin{algorithm}
\caption{\directQuote[Modified from Algorithm 4, p. 4]{$Select(\cdot)$ with Successive Rejects}{pryzant2023AutomaticPrompt}}
\label{alg:gradient_descent_select}
\begin{algorithmic}[1]
    \State Initialize: $S_0 \gets \{p_1, \dots , p_n\}$
    \For{$k = 1, \dots , {n  - 1}$}
        \State Sample $D_{sample} \subset D_{tr}, |D_{sample}| = n(k)$
        \State Evaluate $p_i \in S_{k-1}$ with $m(p_i, D_{sample})$
        \State $S_k \gets S_{k-1}$, excluding the prompt with the lowest score from the previous step
    \EndFor
    \State \Return Best prompt $p^* \in S_{n-1}$
\end{algorithmic}
\end{algorithm}