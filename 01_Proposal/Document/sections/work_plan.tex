\chapter{Work Plan}

\section{Phases}
\subsection{Initial Overview}
\label{phase_initial_overview}

To get familiar with the LiSSA framework, I will implement another basic classifier with simple the simple prompting technique tree-of-thought (ToT) \cite{long2023LargeLanguage}. 
Currently, a zero-shot and chain-of-thought style reasoning classifier are implemented. However, as \citeauthor{long2023LargeLanguage} has shown, tree-of-though style prompts can improve performance compared to chain-of-though approaches in solving logic puzzles. They have tested their approach to ToT prompting with different sized Sudoku puzzles and compared their results against zero-shot prompting as well as chain-of-thought styled one- and few-shot prompting. 


\subsection{Naive iterative Optimization}
\label{phase_naive_iterative}
Next, I plan to implement a naive iterative approach to prompt optimization. Many automatic prompt optimization algorithms \citeiterative  depend on an iterative core loop, which will be repeated until the optimized prompt performs good enough or a maximum number of iterations has been reached.

\subsection{Automatic Prompt Optimization Based on Gradient Descent}
\label{phase_gradient_descent}
The major implementation of this thesis will be an adaption of the gradient descent based automatic prompt optimization (APO) algorithm by \citewithauthor{pryzant2023AutomaticPrompt}. 
The APO algorithm will be trained and tested on the requirements to requirements benchmark data of \citeauthor{hey2025RequirementsTraceability}, available in their replication package \cite{hey2025ReplicationPackage}. The optimized prompt will be compared against previous prompts used by \citeauthor{fuchss2025LiSSAGeneric} and \citeauthor{hey2025RequirementsTraceability} in the greater LiSSA framework.


\subsection{Evaluation and Buffer}
\label{phase_evaluation}
As this work can be seen as an expansion on the recent work of \citewithauthor{hey2025RequirementsTraceability} the same metrics will be used to evaluate the different prompts used and optimized in this work. These are the precision, recall, $F_1$-Score and $F_2$-Score. This enables an easy comparison, especially with the manual prompts designed by \citewithauthor{ewald2024RetrievalAugmentedLarge} included in the work of \citeauthor{hey2025RequirementsTraceability}.









\section{Artifacts}
This work will yield code to be merged into the LiSSA repository\footnote{https://github.com/ArDoCo/LiSSA-RATLR/}. The implementation of \ref{phase_naive_iterative} and \ref{phase_gradient_descent} will provide a base to add further automatic prompt optimization techniques with similar building blocks.

A written report will be created to document, summarize and evaluate the results of my (automatic) prompt optimization work to retrieve trace links.



\ganttset{%
        calendar week text={%
            \currentweek
        }%
    }

\begin{figure}[h!]
    \section{Schedule}
    \begin{center}
    \begin{ganttchart}[
    vgrid={*{6}{draw=none}, dotted},
    x unit=.09cm,
    y unit title=.8cm,
    y unit chart=.8cm,
    milestone left shift =-1,
    milestone right shift =1,
    time slot format=isodate,
    time slot format/start date=2025-06-23]{2025-06-23}{2025-10-26}
    \ganttset{bar height=.7}
        \gantttitlecalendar{year, month=name, week=26} \\
        \ganttgroup{\nameref{phase_initial_overview}}{2025-06-23}{2025-07-27} \\
        \ganttbar{LiSSA setup}{2025-06-23}{2025-07-06} \\
        \ganttbar{ToT implementation}{2025-07-07}{2025-07-13} \\
        \ganttbar[name=impl1]{Benchmark setup}{2025-07-21}{2025-08-03} \\
        \ganttgroup{Naive optimization}{2025-07-28}{2025-08-18} \\
        \ganttbar[name=impl2]{Iterative classifier}{2025-07-28}{2025-08-03} \\
        \ganttgroup{APO gradient descent}{2025-08-25}{2025-09-21} \\
        \ganttbar[name=impl3]{Implementation}{2025-08-25}{2025-09-10}\\
        \ganttmilestone{Code review}{2025-09-07} \\ 
        \ganttbar{Thesis writing}{2025-09-07}{2025-10-04} \\

        
        \ganttgroup{\nameref{phase_evaluation}}{2025-08-11}{2025-10-23} \\
        \ganttbar[name=eval1]{Evaluation}{2025-08-11}{2025-08-24}
        \ganttbar[name=eval2]{}{2025-09-15}{2025-09-28}
    
        \\
    
        \ganttbar{Buffer}{2025-07-14}{2025-07-20}
        \ganttbar{}{2025-08-04}{2025-08-10}
        \ganttbar{}{2025-09-15}{2025-09-21}
        \ganttbar{}{2025-10-05}{2025-10-23}
    
        \\
    
        \ganttmilestone{Thesis hand-in}{2025-10-23}

        \ganttlink{impl1}{eval1}
        \ganttlink{impl2}{eval1}
        \ganttlink{impl3}{eval2}
      
    \end{ganttchart}
    \end{center}
    \caption{Gant chart for thesis plan}
\end{figure}

\section{Risk Management}
The main risk of my work would be failing to implement the automatic prompt optimization in \ref{phase_gradient_descent}. By choosing an optimization algorithm that has Python ode publicly available this risk is already greatly reduced. Furthermore, all three work packages with an implementation content will yield a classifier that can be tested and evaluated against the existing classifiers in the LiSSA Framework. 

As it is hard to estimate the actual required time for each task frequent buffer slots are planned as well, in order to dynamically allocate more time if needed.